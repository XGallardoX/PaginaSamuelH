<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Lab: Im√°genes, Sonidos y Posturas</title>

  <!-- Estilos -->
  <link rel="stylesheet" href="styles.css" />

  <!-- TensorFlow.js (√∫nica dependencia externa obligatoria) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
</head>
<body>
  <div class="app-shell">
    <header class="app-header">
      <div class="header-main">
        <div>
          <h1>AI Lab: Im√°genes, Sonidos y Posturas</h1>
          <p class="header-subtitle">
            Laboratorio de IA multimodal para estudiantes de
            <span class="brand">IA-VISION-CODERS</span>:
            conecta modelos de c√°mara y micr√≥fono a una web interactiva.
          </p>
        </div>
        <div class="header-badges">
          <span class="badge badge-outline">100% en el navegador</span>
          <span class="badge badge-outline">TensorFlow.js</span>
          <span class="badge badge-outline">Demo educativa</span>
        </div>
      </div>

      <nav class="mode-tabs">
        <button class="tab-button active" data-mode="images">
          Im√°genes
        </button>
        <button class="tab-button" data-mode="audio">
          Sonidos
        </button>
        <button class="tab-button" data-mode="postures">
          Posturas
        </button>
      </nav>
    </header>

    <main class="app-main">
      <!-- MODO: IM√ÅGENES -->
      <section id="mode-images" class="mode-panel active">
        <div class="mode-layout">
          <!-- Columna izquierda: entrada -->
          <div class="column column-left">
            <div class="card io-card">
              <div class="card-header">
                <h2>Im√°genes ‚Äì Accesorios en el rostro</h2>
                <p class="card-subtitle">
                  Usa la webcam o sube una imagen para detectar capucha, tapabocas, gafas o sin accesorios.
                </p>
              </div>

              <div class="io-body">
                <div class="video-wrapper">
                  <video id="images-video" autoplay playsinline muted></video>
                  <canvas id="images-canvas"></canvas>
                  <div class="video-label">Webcam</div>
                </div>

                <div class="io-actions">
                  <button id="images-start-btn" class="btn btn-primary">
                    Iniciar
                  </button>
                  <button id="images-stop-btn" class="btn">
                    Detener
                  </button>

                  <label class="btn btn-ghost">
                    Subir imagen
                    <input
                      type="file"
                      id="images-upload"
                      accept="image/*"
                      hidden
                    />
                  </label>
                </div>

                <p class="latency" id="images-latency">
                  Latencia estimada: -- ms
                </p>
              </div>
            </div>
          </div>

          <!-- Columna derecha: salida -->
          <div class="column column-right">
            <div class="card predictions-card">
              <h3>Predicci√≥n Top-1</h3>
              <div class="top1">
                <span id="images-top1-label" class="top1-label">‚Äì</span>
                <span id="images-top1-percent" class="top1-percent">‚Äì %</span>
              </div>
            </div>

            <div class="card predictions-card">
              <h3>Top-3 clases</h3>
              <div id="images-top3-list" class="top3-list">
                <!-- Se rellena din√°micamente desde app.js -->
              </div>
            </div>

            <div class="card about-card">
              <div class="about-header">
                <h3>Acerca del modelo</h3>
                <div class="badges">
                  <span class="badge badge-teachable">Teachable Machine</span>
                  <span class="badge badge-input">Webcam</span>
                  <span class="badge badge-input">Archivo de ejemplo</span>
                </div>
              </div>
              <p>
                Este es un modelo de clasificaci√≥n de <strong>visi√≥n por computador</strong> que recibe
                como entrada la c√°mara o una imagen subida por el usuario. Fue entrenado con ejemplos reales
                de estudiantes para clasificar si una persona tiene <strong>capucha</strong>, <strong>tapabocas</strong>,
                <strong>gafas</strong> o <strong>ning√∫n accesorio</strong>.
              </p>
              <p>
                El modelo se entren√≥ principalmente en <strong>Teachable Machine</strong> y luego se export√≥
                a <strong>TensorFlow.js</strong> para ejecutarse directamente en el navegador, sin enviar
                las im√°genes a ning√∫n servidor.
              </p>
              <p>
                Como toda IA, tiene limitaciones: puede fallar con <strong>mala iluminaci√≥n</strong>,
                <strong>c√°maras de baja calidad</strong> o cuando la cara est√° muy girada o parcialmente
                oculta. Aun as√≠, es ideal como prototipo educativo para seguridad o control de accesorios
                en entornos escolares.
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- MODO: AUDIO -->
      <section id="mode-audio" class="mode-panel">
        <div class="mode-layout">
          <!-- Columna izquierda: entrada -->
          <div class="column column-left">
            <div class="card io-card">
              <div class="card-header">
                <h2>Sonidos ‚Äì Idioma predominante</h2>
                <p class="card-subtitle">
                  Graba audio o sube un archivo para estimar si se habla ingl√©s, franc√©s, espa√±ol o ruso.
                </p>
              </div>

              <div class="io-body">
                <div class="audio-visual">
                  <div class="audio-wave-placeholder">
                    üéß
                  </div>
                  <p class="audio-help">
                    Conecta tu micr√≥fono, presiona <strong>Grabar</strong> y habla unos segundos
                    en el idioma que quieras probar. Tambi√©n puedes subir un archivo .wav/.mp3.
                  </p>

<!-- Audio grabado -->
<div id="audio-playback-container" class="audio-playback hidden">
  <p class="audio-recorded-label">Audio grabado:</p>
  <audio id="audio-playback" controls></audio>
</div>

                </div>

                <div class="io-actions">
                  <button id="audio-record-btn" class="btn btn-primary">
                    Grabar
                  </button>
                  <button id="audio-stop-btn" class="btn">
                    Detener
                  </button>

                  <label class="btn btn-ghost">
                    Subir audio
                    <input
                      type="file"
                      id="audio-upload"
                      accept="audio/*"
                      hidden
                    />
                  </label>
                </div>

                <p class="latency" id="audio-latency">
                  Latencia estimada: -- ms
                </p>
              </div>
            </div>
          </div>

          <!-- Columna derecha: salida -->
          <div class="column column-right">
            <div class="card predictions-card">
              <h3>Predicci√≥n Top-1</h3>
              <div class="top1">
                <span id="audio-top1-label" class="top1-label">‚Äì</span>
                <span id="audio-top1-percent" class="top1-percent">‚Äì %</span>
              </div>
            </div>

            <div class="card predictions-card">
              <h3>Top-3 clases</h3>
              <div id="audio-top3-list" class="top3-list">
                <!-- Se rellena din√°micamente desde app.js -->
              </div>
            </div>

            <div class="card about-card">
              <div class="about-header">
                <h3>Acerca del modelo</h3>
                <div class="badges">
                  <span class="badge badge-tf">TensorFlow + Colab</span>
                  <span class="badge badge-input">Micr√≥fono</span>
                  <span class="badge badge-input">Archivo de ejemplo</span>
                </div>
              </div>
              <p>
                Este es un modelo de <strong>clasificaci√≥n de audio</strong> que recibe como entrada
                el micr√≥fono o un archivo .wav/.mp3. Su objetivo es reconocer el idioma predominante
                en un clip corto entre <strong>ingl√©s</strong>, <strong>franc√©s</strong>,
                <strong>espa√±ol</strong> y <strong>ruso</strong>.
              </p>
              <p>
                El modelo se entren√≥ con <strong>TensorFlow en Python</strong> usando
                <strong>Google Colab</strong>, y luego se convirti√≥ a <strong>TensorFlow.js</strong>
                para ejecutarse en el navegador. Los ejemplos de entrenamiento provienen
                de grabaciones reales hechas por estudiantes.
              </p>
              <p>
                El desempe√±o puede verse afectado por <strong>ruido de fondo</strong>,
                m√∫sica superpuesta o fragmentos de audio muy cortos. Esta demo se centra en
                mostrar la idea general y la integraci√≥n del modelo con la web.
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- MODO: POSTURAS -->
      <section id="mode-postures" class="mode-panel">
        <div class="mode-layout">
          <!-- Columna izquierda: entrada -->
          <div class="column column-left">
            <div class="card io-card">
              <div class="card-header">
                <h2>Posturas ‚Äì Acciones tipo pelea/deporte</h2>
                <p class="card-subtitle">
                  Usa la webcam para clasificar movimientos como punch, kick, fencing, sword_fight o boxing.
                </p>
              </div>

              <div class="io-body">
                <div class="video-wrapper">
                  <video id="postures-video" autoplay playsinline muted></video>
                  <canvas id="postures-canvas"></canvas>
                  <div class="video-label">Webcam</div>
                </div>

                <div class="io-actions">
                  <button id="postures-start-btn" class="btn btn-primary">
                    Iniciar
                  </button>
                  <button id="postures-stop-btn" class="btn">
                    Detener
                  </button>

                  <label class="btn btn-ghost">
                    Subir imagen
                    <input
                      type="file"
                      id="postures-upload"
                      accept="image/*"
                      hidden
                    />
                  </label>
                </div>

                <p class="latency" id="postures-latency">
                  Latencia estimada: -- ms
                </p>
              </div>
            </div>
          </div>

          <!-- Columna derecha: salida -->
          <div class="column column-right">
            <div class="card predictions-card">
              <h3>Predicci√≥n Top-1</h3>
              <div class="top1">
                <span id="postures-top1-label" class="top1-label">‚Äì</span>
                <span id="postures-top1-percent" class="top1-percent">‚Äì %</span>
              </div>
            </div>

            <div class="card predictions-card">
              <h3>Top-3 clases</h3>
              <div id="postures-top3-list" class="top3-list">
                <!-- Se rellena din√°micamente desde app.js -->
              </div>
            </div>

            <div class="card about-card">
              <div class="about-header">
                <h3>Acerca del modelo</h3>
                <div class="badges">
                  <span class="badge badge-teachable">Teachable Machine</span>
                  <span class="badge badge-input">Webcam</span>
                  <span class="badge badge-input">Archivo de ejemplo</span>
                </div>
              </div>
              <p>
                Este es un modelo de <strong>clasificaci√≥n de posturas y acciones</strong> que utiliza
                la c√°mara para detectar movimientos como <strong>punch</strong>, <strong>kick</strong>,
                <strong>fencing</strong>, <strong>sword_fight</strong> y <strong>boxing</strong>.
                Est√° pensado como una demo l√∫dica/deportiva para practicar IA aplicada a visi√≥n.
              </p>
              <p>
                El modelo se entren√≥ principalmente en <strong>Teachable Machine</strong> con
                videos e im√°genes de estudiantes representando cada movimiento, y luego se export√≥
                a <strong>TensorFlow.js</strong>.
              </p>
              <p>
                Funciona mejor cuando la persona est√° <strong>bien iluminada</strong> y se ve el cuerpo
                completo o la parte relevante de la acci√≥n. Puede confundirse con posturas muy distintas
                a las vistas en entrenamiento o con movimientos demasiado r√°pidos.
              </p>
            </div>
          </div>
        </div>
      </section>
    </main>

    <footer class="app-footer">
      <span>AI Lab Multimodal ¬∑ Demo educativa para estudiantes ¬∑ Ejecutando modelos en tu navegador üöÄ</span>
    </footer>
  </div>

  <!-- L√≥gica de la demo -->
  <script src="app.js"></script>
</body>
</html>